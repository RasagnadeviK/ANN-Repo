{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzHG6Ex9SxKxz5bfOEeYBW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RasagnadeviK/ANN-Repo/blob/main/ANN_Lab_6_Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnjHe7Qu74Ka",
        "outputId": "0c17fb92-53fa-44bd-fe45-dbb881fdfcd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Function\n",
            "0.5931263847455048\n",
            "0.5967354892708422\n",
            "\n",
            "Output Function\n",
            "0.7510160015547289\n",
            "0.7725624128682237\n",
            "\n",
            "Error is: 0.2981919094289234\n",
            "-1.4820320031094578 0.07479638678539054\n",
            "0.4348751742635526 0.08002266041568873\n",
            "New weight 4 is: 0.43802538526979823\n",
            "-1.4820320031094578 0.08414593513356436\n",
            "0.4348751742635526 0.09002549296764982\n",
            "New weight 5 is: 0.49277855842852303\n",
            "-1.4820320031094578 0.09349548348173817\n",
            "0.4348751742635526 0.1000283255196109\n",
            "New weight 6 is: 0.5475317315872478\n",
            "-1.4820320031094578 0.10284503182991199\n",
            "0.4348751742635526 0.11003115807157199\n",
            "New weight 7 is: 0.6022849047459725\n",
            "[0.15, 0.2, 0.25, 0.3, 0.43802538526979823, 0.49277855842852303, 0.5475317315872478, 0.6022849047459725]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "t=[0.01,0.99]\n",
        "a=0.5 #learning rate\n",
        "\n",
        "#Inputs\n",
        "x1=0.05;x2=0.10\n",
        "\n",
        "#bias values\n",
        "b1=0.35;b2=0.60\n",
        "\n",
        "#OverAll Weights\n",
        "wt=[0.15,0.20,0.25,0.30,0.40,0.45,0.50,0.55]\n",
        "\n",
        "#Activation Function\n",
        "def sigmoidfun(n):\n",
        "  x=1+pow(2.714,-n)\n",
        "  return 1/x\n",
        "\n",
        "#Gradient Descent Function\n",
        "def gradFun(y):\n",
        "  for j in range(4,8):\n",
        "    for i in range(len(t)):\n",
        "      dx=(t[i]-y[i])*2\n",
        "      dy=y[i]*(1-y[i])*wt[j]\n",
        "      print(dx,dy)\n",
        "      dx=dx*dy\n",
        "      wt[j]=wt[j]-(a*dx)\n",
        "    print('New weight',j,'is:',wt[j])\n",
        "  print(wt)\n",
        "\n",
        "#Error calculation function\n",
        "def errorFun(od):\n",
        "  tot=0\n",
        "  for i in range(len(od)):\n",
        "    x=(t[i]-od[i])**2\n",
        "    #print(x/2)\n",
        "    tot+=(x/2)\n",
        "  print('\\nError is:',tot)\n",
        "\n",
        "#Output calculation Function\n",
        "def outputFun(h):\n",
        "  print(\"\\nOutput Function\")\n",
        "  lst=[]\n",
        "  for i in range(4,8,2):\n",
        "    temp=h[0]*wt[i]+h[1]*wt[i+1]\n",
        "    temp+=b2\n",
        "    ans=sigmoidfun(temp)\n",
        "    print(ans)\n",
        "    lst.append(ans)\n",
        "  errorFun(lst)\n",
        "  gradFun(lst)\n",
        "\n",
        "#Hidden layer function\n",
        "def hiddenFun():\n",
        "  print(\"Hidden Function\")\n",
        "  lst=[]\n",
        "  for i in range(0,4,2):\n",
        "    temp=x1*wt[i]+x2*wt[i+1]\n",
        "    temp+=b1\n",
        "    ans=sigmoidfun(temp)\n",
        "    print(ans)\n",
        "    lst.append(ans)\n",
        "  outputFun(lst)\n",
        "\n",
        "#initially calling hidden layer function\n",
        "hiddenFun()"
      ]
    }
  ]
}
